# Data Structures & Algorithms

## Array

- 여러 data가 메모리 덩어리 안에 줄줄이 나열된 가장 간단한 구조
- data에는 index로 접근

### 시간복잡도

* Average
    * 검색 - O(n)
    * 삽입 - O(n)
    * 삭제 - O(n)
* Worst
    * 검색 - O(n)
    * 삽입 - O(n)
    * 삭제 - O(n)

## Stack

- First In, Last Out

### 시간복잡도

* Average
    * 검색 - O(n)
    * 삽입 - O(1)
    * 삭제 - O(1)
* Worst
    * 검색 - O(n)
    * 삽입 - O(1)
    * 삭제 - O(1)

## Queue

- First In, First Out

### 시간복잡도

* Average
    * 검색 - O(n)
    * 삽입 - O(1)
    * 삭제 - O(1)
* Worst
    * 검색 - O(n)
    * 삽입 - O(1)
    * 삭제 - O(1)

## Linked List

- 메모리에서 연속되어 있지 않음. 각 노드가 포인터로 연결되어 있음. 
- 빈번한 삽입, 삭제에 유리함. 

### 시간복잡도

* Average
    * 검색 - O(n)
    * 삽입 - O(1)
    * 삭제 - O(1)
* Worst
    * 검색 - O(n)
    * 삽입 - O(1)
    * 삭제 - O(1)

## Hash Table

- hash function: 임의의 길이의 데이터를 고정된 길이의 데이터로 매핑하는 함수
    - 결정론적으로 작동한다. 
    - 두 해시 값이 다르다면 그 해시 값에 대한 원래 데이터도 다르다. (역은 성립하지 않는다. 두 키 사이에 충돌이 존재할 수 있다.)
    - ex) DJB2, FNV-1, CRC32...
- 균일성
    - 해시함수의 출력값이 고르게 분포될수록 균일성이 높음 -> 충돌이 적어짐
    - hash table의 크기는 데이터의 수의 2배보다 큰 소수를 사용하는 것이 충돌이 날 가능성이 낮다. 
    - 입력값이 조금만 달라져도 결과값이 크게 달라지면 좋다.(눈사태 효과) -> 해시 값을 토대로 입력값을 유추하기 어렵다. 
    - 지역 민감 해시(locality sensitive hashing) -> 균일성이 높은게 항상 좋은 게 아니라는 예시
        - 비슷한 내용을 가진 데이터끼리 충돌해야 함
        - ex) 스팸 메일 찾기, 검색 엔진에서 비슷한 문서 추천하기, 저작권 침해 검사...
- 효율성
    - 충돌이 좀 나더라도 더 빠른 함수를 선호하는 경우

### 시간복잡도

* Average
    * 검색 - O(1)
    * 삽입 - O(1)
    * 삭제 - O(1)
* Worst
    * 검색 - O(n)
    * 삽입 - O(n)
    * 삭제 - O(n)

## Recursion

재귀함수로 작성한 코드는 반복문으로도 변경이 가능하다. stack overflow가 발생할 가능성이 있거나, 성능 문제가 일어날 가능성이 크거나, 성능 문제가 확인된 경우, 재귀함수로 작성한 코드는 반복문으로 변경한다. 

- 장점
    - 가독성이 높고 코드가 짧음
    - 코드 검증이 쉬움
    - 변수 사용이 줄어든다(mutable state를 가능한 피하는 것은 오류 없는 프로그램을 짜는 것에 도움이 된다.)
- 단점
    - 재귀적 문제 분석 / 설계가 직관적이지 않음
    - stack overflow 발생 가능
- 꼬리 재귀
    - tail call optimization이 지원되는 경우에만 성능상 이득이 있다. ex) C / C++ (gcc, clang), Rust...
    - 꼬리 재귀는 반복문으로 쉽게 변경이 가능함

## Binary Search

- 정렬된 배열에서 어떤 값의 위치를 찾는 알고리즘. 
- 분할 정복(divide and conquer) 알고리즘 중 하나. 

### 시간복잡도

평균 O(log n)

## Sorting Algorithms
